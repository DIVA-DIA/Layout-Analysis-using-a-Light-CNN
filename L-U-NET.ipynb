{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DIVA-DIA/Layout-Analysis-using-a-Light-CNN/blob/main/L-U-NET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "VHJcjNKnFlgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import albumentations as albu\n",
        "\n",
        "import time\n",
        "import glob\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from torchvision.datasets.folder import pil_loader\n",
        "import random\n",
        "import torch.nn.init as init"
      ],
      "metadata": {
        "id": "Us9hVMTWZbqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "cd='/content/drive/My Drive/Colab Notebooks/'\n",
        "%cd /content/drive/My Drive/Colab Notebooks/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbXoX5xcZchS",
        "outputId": "959af5b7-d64f-4d8d-f27a-695f5565ad82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_DIR = 'path_to_images'\n",
        "mask_DIR = 'path_to_groundtruth'"
      ],
      "metadata": {
        "id": "pFrL8R-EZhLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_dir = os.path.join(img_DIR, 'training')\n",
        "y_train_dir = os.path.join(mask_DIR, 'training')\n",
        "\n",
        "x_valid_dir = os.path.join(img_DIR, 'validation')\n",
        "y_valid_dir = os.path.join(mask_DIR, 'validation')\n",
        "\n",
        "x_test_dir = os.path.join(img_DIR, 'public-test')\n",
        "y_test_dir = os.path.join(mask_DIR, 'public-test')"
      ],
      "metadata": {
        "id": "1dm9CPvFZ4vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('the number of image/label in the train: ',len(os.listdir(x_train_dir)))\n",
        "print('the number of image/label in the validation: ',len(os.listdir(x_valid_dir)))\n",
        "print('the number of image/label in the test: ',len(os.listdir(x_test_dir)))"
      ],
      "metadata": {
        "id": "jaW8qKn1Z6-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_paths = glob.glob(os.path.join(x_train_dir, \"*.jpg\"))\n",
        "train_mask_paths = glob.glob(os.path.join(y_train_dir, \"*.gif\"))\n",
        "val_img_paths = glob.glob(os.path.join(x_valid_dir, \"*.jpg\"))\n",
        "val_mask_paths = glob.glob(os.path.join(y_valid_dir, \"*.gif\"))\n",
        "test_img_paths = glob.glob(os.path.join(x_test_dir, \"*.jpg\"))\n",
        "test_mask_paths = glob.glob(os.path.join(y_test_dir, \"*.gif\"))"
      ],
      "metadata": {
        "id": "xt4b-YO7Z9Yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_paths.sort()\n",
        "train_mask_paths.sort()"
      ],
      "metadata": {
        "id": "-h7PUxDFaCGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_img_paths[:5])\n",
        "print(train_mask_paths[:5])"
      ],
      "metadata": {
        "id": "KDUr3y0HaEY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_img_paths.sort()\n",
        "val_mask_paths.sort()"
      ],
      "metadata": {
        "id": "LpYMvKzkaHEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_img_paths[:5])\n",
        "print(val_mask_paths[:5])"
      ],
      "metadata": {
        "id": "Ck7TdbZKaJCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_paths.sort()\n",
        "test_mask_paths.sort()"
      ],
      "metadata": {
        "id": "-Gt7DLCMaL14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_img_paths[:5])\n",
        "print(test_mask_paths[:5])"
      ],
      "metadata": {
        "id": "jBbANjffaOnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#labels\n",
        "background = [0,0,0] #black\n",
        "comments = [0, 255, 0] #green\n",
        "decor = [255, 0, 0] #red\n",
        "text = [0, 0, 255] #blue"
      ],
      "metadata": {
        "id": "04C5-K_CVppD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mask from RGB to labels (HxW)\n",
        "def rgb_to_2D_label(label):\n",
        "    \"\"\"\n",
        "    Suply our labale masks as input in RGB format. \n",
        "    Replace pixels with specific RGB values ...\n",
        "    \"\"\"\n",
        "    label_seg = np.zeros(label.shape,dtype=np.uint8)\n",
        "    label_seg [np.all(label == background,axis=-1)] = 0\n",
        "    label_seg [np.all(label==comments,axis=-1)] = 1\n",
        "    label_seg [np.all(label==decor,axis=-1)] = 2\n",
        "    label_seg [np.all(label==text,axis=-1)] = 3\n",
        "    \n",
        "    label_seg = label_seg[:,:,0]  #Just take the first channel, no need for all 3 channels\n",
        "    \n",
        "    return label_seg"
      ],
      "metadata": {
        "id": "Ue7FLds3VsV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DIVA(Dataset):\n",
        "\n",
        "    def __init__(\n",
        "            self, \n",
        "            imagePaths, \n",
        "            maskPaths, \n",
        "\n",
        "    ):\n",
        "        self.imagePaths = imagePaths\n",
        "        self.maskPaths = maskPaths\n",
        "\n",
        "        \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # read data\n",
        "            img_path = self.imagePaths[idx]\n",
        "            mask_path = self.maskPaths[idx]\n",
        "            read_img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "            read_img = cv2.resize(read_img, (1152,1728), interpolation = cv2.INTER_AREA)\n",
        "            img = 2*((read_img - read_img.min()) / (read_img.max() - read_img.min())) - 1\n",
        "            mask = pil_loader(mask_path)\n",
        "            #mask to numpy\n",
        "            np_mask_diva = np.array(mask)\n",
        "            #mask from RGB to labels (HxW)\n",
        "            mask = rgb_to_2D_label(np_mask_diva)\n",
        "            #Image and mask normalization\n",
        "            Transforms = transforms.Compose([transforms.ToTensor()])\n",
        "            img = Transforms(img)\n",
        "            mask = torch.from_numpy(mask).long()\n",
        "\n",
        "            return img, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imagePaths)"
      ],
      "metadata": {
        "id": "84A6Hr4faU6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import RandomSampler"
      ],
      "metadata": {
        "id": "vjkfgp5hDCLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sampler(dataset, seed=123):\n",
        "    generator = torch.Generator()\n",
        "    generator.manual_seed(seed)\n",
        "    sampler = RandomSampler(dataset, generator=generator)\n",
        "    return sampler"
      ],
      "metadata": {
        "id": "5YHRo5ozalji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train, Validationのデータセットを作成\n",
        "\n",
        "train_dataset = DIVA(\n",
        "    train_img_paths, \n",
        "    train_mask_paths, \n",
        "    \n",
        ")\n",
        "\n",
        "valid_dataset = DIVA(\n",
        "    val_img_paths, \n",
        "    val_mask_paths, \n",
        "    \n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, sampler=get_sampler(train_dataset), num_workers=0)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "id": "29QSLIeBDHz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the image and corrosponding mask\n",
        "image_batch, mask_batch = next(iter(train_loader))\n",
        "\n",
        "image_batch.shape, mask_batch.shape"
      ],
      "metadata": {
        "id": "l6hyS0z_acMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dil_block(in_c, out_c):\n",
        "    conv = nn.Sequential(\n",
        "        nn.Conv2d(in_c, out_c, kernel_size=3, stride=1, padding=1, dilation=1),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.ReLU(inplace=True),\n",
        "        \n",
        "        nn.Conv2d(out_c, out_c, kernel_size=3, stride=1, padding=1, dilation=1),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.ReLU(inplace=True),\n",
        "        \n",
        "        nn.Conv2d(out_c, out_c, kernel_size=3, stride=1, padding=2, dilation=2),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.Conv2d(out_c, out_c, kernel_size=3, stride=1, padding=2, dilation=2),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.ReLU(inplace=True),\n",
        "        \n",
        "        \n",
        "        )\n",
        "    return conv\n",
        "\n",
        "\n",
        "def encoding_block(in_c, out_c):\n",
        "    conv = nn.Sequential(\n",
        "        nn.Conv2d(in_c, out_c, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.ReLU(inplace=True),\n",
        "        \n",
        "        )\n",
        "    return conv\n",
        "\n",
        "def encoding_block1(in_c, out_c):\n",
        "    conv = nn.Sequential(\n",
        "        nn.Conv2d(in_c, out_c, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.ReLU(inplace=True),\n",
        "        \n",
        "        nn.Conv2d(out_c, out_c, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.ReLU(inplace=True),\n",
        "        \n",
        "        )\n",
        "    return conv"
      ],
      "metadata": {
        "id": "2nHmL3XFZ1lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaeRNrQDZOMN"
      },
      "outputs": [],
      "source": [
        "class unet_model(nn.Module):\n",
        "    def __init__(self,out_channels=4,features=[16, 32]):\n",
        "        super(unet_model,self).__init__()\n",
        "        \n",
        "        \n",
        "        self.dil1 = dil_block(3,features[0])\n",
        "        \n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "        \n",
        "        self.dil2 = dil_block(features[0],features[0])\n",
        "        \n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "        \n",
        "        self.dil3 = dil_block(features[0],features[0])\n",
        "        \n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "        \n",
        "        self.dil4 = dil_block(features[0],features[0])\n",
        "        \n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "        \n",
        "        self.bott = encoding_block1(features[0],features[0])\n",
        "        \n",
        "        self.tconv1 = nn.ConvTranspose2d(features[0], features[0], kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv1 = encoding_block(features[1],features[0])\n",
        "        \n",
        "        self.tconv2 = nn.ConvTranspose2d(features[0], features[0], kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv2 = encoding_block(features[1],features[0])\n",
        "        \n",
        "        self.tconv3 = nn.ConvTranspose2d(features[0], features[0], kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv3 = encoding_block(features[1],features[0])\n",
        "        \n",
        "        self.tconv4 = nn.ConvTranspose2d(features[0], features[0], kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv4 = encoding_block1(features[1],features[0])\n",
        "        \n",
        "        \n",
        "        self.final_layer = nn.Conv2d(features[0],out_channels, kernel_size=1)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        dil_1 = self.dil1(x) \n",
        "        \n",
        "        pool_1 = self.pool1(dil_1)\n",
        "        \n",
        "        dil_2 = self.dil2(pool_1) \n",
        "        \n",
        "        pool_2 = self.pool2(dil_2) \n",
        "        \n",
        "        dil_3 = self.dil3(pool_2) \n",
        "        \n",
        "        pool_3 = self.pool3(dil_3) \n",
        "        \n",
        "        dil_4 = self.dil4(pool_3) \n",
        "        \n",
        "        pool_4 = self.pool3(dil_4) \n",
        "        \n",
        "        bott = self.bott(pool_4) \n",
        "        \n",
        "        tconv_1 = self.tconv1(bott) \n",
        "        \n",
        "        concat1 = torch.cat((tconv_1, dil_4), dim=1) \n",
        "        \n",
        "        conv_1 = self.conv1(concat1) \n",
        "        \n",
        "        tconv_2 = self.tconv2(conv_1) \n",
        "        \n",
        "        concat2 = torch.cat((tconv_2, dil_3), dim=1)\n",
        "        \n",
        "        conv_2 = self.conv2(concat2) \n",
        "        \n",
        "        tconv_3 = self.tconv3(conv_2) \n",
        "        \n",
        "        concat3 = torch.cat((tconv_3, dil_2), dim=1) \n",
        "        \n",
        "        conv_3 = self.conv3(concat3) \n",
        "        \n",
        "        tconv_4 = self.tconv4(conv_3) \n",
        "        \n",
        "        concat4 = torch.cat((tconv_4, dil_1), dim=1) \n",
        "        \n",
        "        conv_4 = self.conv4(concat4) \n",
        "        \n",
        "        \n",
        "        x = self.final_layer(conv_4)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"gpu\""
      ],
      "metadata": {
        "id": "Zh39vmrmah4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initilize the model\n",
        "model = unet_model().to(device)"
      ],
      "metadata": {
        "id": "uWZ-Oim5awHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pixel_accuracy(output, mask):\n",
        "    with torch.no_grad():\n",
        "        preds = torch.argmax(F.softmax(output, dim=1), dim=1)\n",
        "        num_correct = (preds == mask).sum()\n",
        "        num_pixels = torch.numel(preds)\n",
        "        accuracy = float(num_correct) / float(num_pixels)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "TEYDfA5Vak0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mIoU(output, mask):\n",
        "    with torch.no_grad():\n",
        "        preds = torch.argmax(F.softmax(output, dim=1), dim=1)\n",
        "        \n",
        "\n",
        "        intersection = torch.logical_and(preds, mask).sum()\n",
        "        union = torch.logical_or(preds, mask).sum()\n",
        "\n",
        "        IoU = float(intersection + 1e-10) / float(union +1e-10)\n",
        "    return IoU"
      ],
      "metadata": {
        "id": "FAhhi4oDamts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-05)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "uasOtxwwgkT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "val_loss = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "train_IoU = []\n",
        "val_IoU = []"
      ],
      "metadata": {
        "id": "muRsDV55azqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_accumulation_steps = 5"
      ],
      "metadata": {
        "id": "by-Hzxd0ONjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_loss = np.Inf\n",
        "best_iou_score = 0.0\n",
        "epochs = 300\n",
        "fit_time = time.time()\n",
        "for epoch in range(epochs):\n",
        "    print('Epoch: [{}/{}]'.format(epoch+1, epochs))\n",
        "    \n",
        "    trainloss = 0\n",
        "    trainaccuracy = 0\n",
        "    trainIoU = 0\n",
        "    \n",
        "    since = time.time()\n",
        "    model.train()\n",
        "    #for img,label in tqdm(train_loader):\n",
        "    for index, batch in enumerate(train_loader):\n",
        "        img, label = batch\n",
        "        '''\n",
        "            Traning the Model.\n",
        "        '''\n",
        "        optimizer.zero_grad()\n",
        "        img=img.float() \n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        model = model.cuda()\n",
        "        output = model(img)\n",
        "        loss = criterion(output,label)\n",
        "        loss.backward()\n",
        "        if (index + 1) % gradient_accumulation_steps == 0:\n",
        "           optimizer.step()\n",
        "        #scheduler.step()\n",
        "        trainloss+=loss.item()\n",
        "        trainaccuracy += pixel_accuracy(output, label)\n",
        "        trainIoU += mIoU(output, label)\n",
        "    \n",
        "    #if(i%5==0):\n",
        "        #show(img,output,label)\n",
        "\n",
        "    \n",
        "  \n",
        "    model.eval()\n",
        "    valloss = 0\n",
        "    valaccuracy = 0\n",
        "    valIoU = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for img_val,label_val in tqdm(valid_loader):\n",
        "        '''\n",
        "            Validation of Model.\n",
        "        '''\n",
        "        img_val=img_val.float()\n",
        "        img_val = img_val.to(device)\n",
        "        label_val = label_val.to(device)\n",
        "        model = model.cuda()\n",
        "        output_val = model(img_val)\n",
        "        loss_val = criterion(output_val,label_val)\n",
        "        valloss+=loss_val.item()\n",
        "        valaccuracy += pixel_accuracy(output_val, label_val)\n",
        "        valIoU += mIoU(output_val, label_val)\n",
        "        \n",
        "    train_loss.append(trainloss/len(train_loader))  \n",
        "    train_accuracy.append(trainaccuracy/len(train_loader))\n",
        "    train_IoU.append(trainIoU/len(train_loader))  \n",
        "    val_loss.append(valloss/len(valid_loader)) \n",
        "    val_accuracy.append(valaccuracy/len(valid_loader))\n",
        "    val_IoU.append(valIoU/len(valid_loader)) \n",
        "\n",
        "    # Save model if a better val IoU score is obtained\n",
        "    if best_loss > valloss:\n",
        "         best_loss = valloss\n",
        "         torch.save({\n",
        "            'epoch': epochs,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': criterion,\n",
        "            }, 'path to save the model')\n",
        "         print('Loss_Model saved!') \n",
        "    \n",
        "    # Save model if a better val IoU score is obtained\n",
        "    if best_iou_score < valIoU:\n",
        "         best_iou_score = valIoU\n",
        "         torch.save({\n",
        "            'epoch': epochs,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': criterion,\n",
        "            }, 'path to save the model')\n",
        "         print('IOU_Model saved!')\n",
        "\n",
        "    #print(\"epoch : {} ,train loss : {} ,valid loss : {} ,train acc : {} ,val acc : {} \".format(i,train_loss[-1],val_loss[-1],train_accuracy[-1],val_accuracy[-1]))\n",
        "    print(#\"Epoch:{}\".format(epoch),\n",
        "          \"Train Loss: {}\".format(trainloss/len(train_loader)),\n",
        "          \"Val Loss: {}\".format(valloss/len(valid_loader)), \n",
        "          \"Train mIoU:{}\".format(trainIoU/len(train_loader)),\n",
        "          \"Val mIoU: {}\".format(valIoU/len(valid_loader)),\n",
        "          \"Train Acc:{}\".format(trainaccuracy/len(train_loader)),\n",
        "          \"Val Acc:{}\".format(valaccuracy/len(valid_loader)),\n",
        "          \"Time: {:.2f}m\".format((time.time()-since)/60))\n",
        "print('Total time: {:.2f} m' .format((time.time()- fit_time)/60))"
      ],
      "metadata": {
        "id": "k7zQTJ0Ba1c8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(14, 5))\n",
        "ax1 = fig.add_subplot()\n",
        "plt.plot(train_loss,color='b',label='train loss', marker='o')\n",
        "plt.plot(val_loss,color='r',label = 'val loss', marker='o')\n",
        "ax1.set_title(\"Loss\")\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "CgPuJu83PPU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(14, 5))\n",
        "ax1 = fig.add_subplot()\n",
        "plt.plot(train_IoU,color='b',label='train IoU', marker='*')\n",
        "plt.plot(val_IoU,color='r',label = 'val IoU', marker='*')\n",
        "ax1.set_title(\"IoU\")\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('IoU')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "qyXT-PmY6Orj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(14, 5))\n",
        "ax1 = fig.add_subplot()\n",
        "plt.plot(train_accuracy,color='b',label='train acc', marker='*')\n",
        "plt.plot(val_accuracy,color='r',label = 'val acc', marker='*')\n",
        "ax1.set_title(\"Accuracy\")\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "Z829w3K2PU-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the trained model\n",
        "Test_model = unet_model().to(device) # initilize the model"
      ],
      "metadata": {
        "id": "fE3kklYeroIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model checkpoint\n",
        "Test_checkpoint_iou = torch.load('load the model')\n",
        "# load model weights state_dict\n",
        "Test_model.load_state_dict(Test_checkpoint_iou['model_state_dict'])\n",
        "print('Previously trained model weights state_dict loaded...')"
      ],
      "metadata": {
        "id": "Lf-7myiGrs_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create test dataset\n",
        "test_dataset = DIVA(\n",
        "    test_img_paths, \n",
        "    test_mask_paths, \n",
        ")\n",
        "\n",
        "test_dataloader_realD = DataLoader(test_dataset)"
      ],
      "metadata": {
        "id": "r-8psvQGr6_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSES = ['bg', 'line', 'hline', 'gline']"
      ],
      "metadata": {
        "id": "Bg6s0eKOsXc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import jaccard_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "nb_classes = 4\n",
        "\n",
        "# Initialize the prediction and label lists(tensors)\n",
        "predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "lbllist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(test_dataset):\n",
        "        #inputs = inputs.transpose(2,0,1)\n",
        "        inputs = inputs.to(device).unsqueeze(0)\n",
        "        classes = classes.to(device)\n",
        "        outputs = Test_model(inputs.float())\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        # Append batch prediction results\n",
        "        predlist=torch.cat([predlist,preds.view(-1).cpu()])\n",
        "        lbllist=torch.cat([lbllist,classes.view(-1).cpu()])\n",
        "\n",
        "# Confusion matrix\n",
        "conf_mat=confusion_matrix(lbllist.numpy(), predlist.numpy())\n",
        "print(conf_mat)\n",
        "\n",
        "# Per-class accuracy\n",
        "class_accuracy=100*conf_mat.diagonal()/conf_mat.sum(1)\n",
        "print(class_accuracy)\n",
        "print(classification_report(lbllist.numpy(), predlist.numpy(), target_names = CLASSES))\n",
        "\n",
        "#Jaccard, precision, recall, F1\n",
        "Jaccard = jaccard_score(lbllist.numpy(), predlist.numpy(), average=\"macro\")\n",
        "Jaccard_classes = jaccard_score(lbllist.numpy(), predlist.numpy(), average=None)\n",
        "P_R_F1 = precision_recall_fscore_support(lbllist.numpy(), predlist.numpy(), average=\"macro\")\n",
        "P, R, F1, _ = precision_recall_fscore_support(lbllist.numpy(), predlist.numpy(), average=None)\n",
        "print('Macro Jaccard:', Jaccard)\n",
        "print('Jaccard per class:', Jaccard_classes)\n",
        "print('Macro Precision, Recall, F1:', P_R_F1)\n",
        "print('Precision per class:', P)\n",
        "print('Recall per class:', R)\n",
        "print('F1 per class:', F1)"
      ],
      "metadata": {
        "id": "XPNOf8VBaKRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalise\n",
        "import seaborn as sns\n",
        "cmn = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(cmn, annot=True, fmt='.4f', xticklabels=CLASSES, yticklabels=CLASSES)\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show(block=False)"
      ],
      "metadata": {
        "id": "CISkqaZ-ETnz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "a1649516-83b1-46ac-b620-fc3af07f1629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualization\n",
        "label_name = ['background', 'comments', 'decor', 'text']\n",
        "label_colors = np.array([background, comments, decor, text])"
      ],
      "metadata": {
        "id": "Hz3c1OPQTY3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(temp):\n",
        "    r = temp.copy()\n",
        "    g = temp.copy()\n",
        "    b = temp.copy()\n",
        "    for l in range(len(label_colors)):\n",
        "        r[temp==l]=label_colors[l,0]\n",
        "        g[temp==l]=label_colors[l,1]\n",
        "        b[temp==l]=label_colors[l,2]\n",
        "\n",
        "    rgb = np.zeros((temp.shape[0], temp.shape[1], 3))\n",
        "    rgb[:,:,0] = (r/255.0)#[:,:,0]\n",
        "    rgb[:,:,1] = (g/255.0)#[:,:,1]\n",
        "    rgb[:,:,2] = (b/255.0)#[:,:,2]\n",
        "    return rgb"
      ],
      "metadata": {
        "id": "rofTaKtGTfF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "rwG4c_ShTi9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = Path('path to save predictions')\n",
        "output_path.mkdir(exist_ok=True)"
      ],
      "metadata": {
        "id": "BxHU_UMVTleG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(test_dataset)):\n",
        "\n",
        "        \n",
        "        image, mask = test_dataset[i]\n",
        "        x_tensor = image.to(device).unsqueeze(0)\n",
        "        pr_mask = Test_model(x_tensor.float())\n",
        "        pr_mask_show = (pr_mask.squeeze().cpu().detach().numpy())\n",
        "        pr_mask_show_2=np.argmax(pr_mask_show.transpose((1, 2, 0)), axis=2)\n",
        "        diva_out = (visualize(pr_mask_show_2)*255).astype(np.uint8)\n",
        "        diva_out=Image.fromarray(diva_out)\n",
        "        diva_out.save(f'path to save predictions/image_{i}.gif')"
      ],
      "metadata": {
        "id": "v6cikts0Twwi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}