{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DIVA-DIA/Layout-Analysis-using-a-Light-CNN/blob/main/L_U_NET_architecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "VHJcjNKnFlgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import albumentations as albu\n",
        "\n",
        "import time\n",
        "import glob\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from torchvision.datasets.folder import pil_loader\n",
        "import random\n",
        "import torch.nn.init as init"
      ],
      "metadata": {
        "id": "Us9hVMTWZbqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "cd='/content/drive/My Drive/Colab Notebooks/'\n",
        "%cd /content/drive/My Drive/Colab Notebooks/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbXoX5xcZchS",
        "outputId": "959af5b7-d64f-4d8d-f27a-695f5565ad82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_DIR = 'path_to_images'\n",
        "mask_DIR = 'path_to_groundtruth'"
      ],
      "metadata": {
        "id": "pFrL8R-EZhLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_dir = os.path.join(img_DIR, 'training')\n",
        "y_train_dir = os.path.join(mask_DIR, 'training')\n",
        "\n",
        "x_valid_dir = os.path.join(img_DIR, 'validation')\n",
        "y_valid_dir = os.path.join(mask_DIR, 'validation')\n",
        "\n",
        "x_test_dir = os.path.join(img_DIR, 'public-test')\n",
        "y_test_dir = os.path.join(mask_DIR, 'public-test')"
      ],
      "metadata": {
        "id": "1dm9CPvFZ4vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('the number of image/label in the train: ',len(os.listdir(x_train_dir)))\n",
        "print('the number of image/label in the validation: ',len(os.listdir(x_valid_dir)))\n",
        "print('the number of image/label in the test: ',len(os.listdir(x_test_dir)))"
      ],
      "metadata": {
        "id": "jaW8qKn1Z6-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_paths = glob.glob(os.path.join(x_train_dir, \"*.jpg\"))\n",
        "train_mask_paths = glob.glob(os.path.join(y_train_dir, \"*.gif\"))\n",
        "val_img_paths = glob.glob(os.path.join(x_valid_dir, \"*.jpg\"))\n",
        "val_mask_paths = glob.glob(os.path.join(y_valid_dir, \"*.gif\"))\n",
        "test_img_paths = glob.glob(os.path.join(x_test_dir, \"*.jpg\"))\n",
        "test_mask_paths = glob.glob(os.path.join(y_test_dir, \"*.gif\"))"
      ],
      "metadata": {
        "id": "xt4b-YO7Z9Yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_paths.sort()\n",
        "train_mask_paths.sort()"
      ],
      "metadata": {
        "id": "-h7PUxDFaCGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_img_paths[:5])\n",
        "print(train_mask_paths[:5])"
      ],
      "metadata": {
        "id": "KDUr3y0HaEY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_img_paths.sort()\n",
        "val_mask_paths.sort()"
      ],
      "metadata": {
        "id": "LpYMvKzkaHEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_img_paths[:5])\n",
        "print(val_mask_paths[:5])"
      ],
      "metadata": {
        "id": "Ck7TdbZKaJCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_paths.sort()\n",
        "test_mask_paths.sort()"
      ],
      "metadata": {
        "id": "-Gt7DLCMaL14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_img_paths[:5])\n",
        "print(test_mask_paths[:5])"
      ],
      "metadata": {
        "id": "jBbANjffaOnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#labels\n",
        "background = [0,0,0] #black\n",
        "comments = [0, 255, 0] #green\n",
        "decor = [255, 0, 0] #red\n",
        "text = [0, 0, 255] #blue"
      ],
      "metadata": {
        "id": "04C5-K_CVppD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mask from RGB to labels (HxW)\n",
        "def rgb_to_2D_label(label):\n",
        "    \"\"\"\n",
        "    Suply our labale masks as input in RGB format.\n",
        "    Replace pixels with specific RGB values ...\n",
        "    \"\"\"\n",
        "    label_seg = np.zeros(label.shape,dtype=np.uint8)\n",
        "    label_seg [np.all(label == background,axis=-1)] = 0\n",
        "    label_seg [np.all(label==comments,axis=-1)] = 1\n",
        "    label_seg [np.all(label==decor,axis=-1)] = 2\n",
        "    label_seg [np.all(label==text,axis=-1)] = 3\n",
        "\n",
        "    label_seg = label_seg[:,:,0]  #Just take the first channel, no need for all 3 channels\n",
        "\n",
        "    return label_seg"
      ],
      "metadata": {
        "id": "Ue7FLds3VsV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DIVA(Dataset):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            imagePaths,\n",
        "            maskPaths,\n",
        "\n",
        "    ):\n",
        "        self.imagePaths = imagePaths\n",
        "        self.maskPaths = maskPaths\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # read data\n",
        "            img_path = self.imagePaths[idx]\n",
        "            mask_path = self.maskPaths[idx]\n",
        "            read_img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "            read_img = cv2.resize(read_img, (1152,1728), interpolation = cv2.INTER_AREA)\n",
        "            img = 2*((read_img - read_img.min()) / (read_img.max() - read_img.min())) - 1\n",
        "            mask = pil_loader(mask_path)\n",
        "            #mask to numpy\n",
        "            np_mask_diva = np.array(mask)\n",
        "            #mask from RGB to labels (HxW)\n",
        "            mask = rgb_to_2D_label(np_mask_diva)\n",
        "            #Image and mask normalization\n",
        "            Transforms = transforms.Compose([transforms.ToTensor()])\n",
        "            img = Transforms(img)\n",
        "            mask = torch.from_numpy(mask).long()\n",
        "\n",
        "            return img, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imagePaths)"
      ],
      "metadata": {
        "id": "84A6Hr4faU6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import RandomSampler"
      ],
      "metadata": {
        "id": "vjkfgp5hDCLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sampler(dataset, seed=123):\n",
        "    generator = torch.Generator()\n",
        "    generator.manual_seed(seed)\n",
        "    sampler = RandomSampler(dataset, generator=generator)\n",
        "    return sampler"
      ],
      "metadata": {
        "id": "5YHRo5ozalji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train, Validationのデータセットを作成\n",
        "\n",
        "train_dataset = DIVA(\n",
        "    train_img_paths,\n",
        "    train_mask_paths,\n",
        "\n",
        ")\n",
        "\n",
        "valid_dataset = DIVA(\n",
        "    val_img_paths,\n",
        "    val_mask_paths,\n",
        "\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, sampler=get_sampler(train_dataset), num_workers=0)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "id": "29QSLIeBDHz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the image and corrosponding mask\n",
        "image_batch, mask_batch = next(iter(train_loader))\n",
        "\n",
        "image_batch.shape, mask_batch.shape"
      ],
      "metadata": {
        "id": "l6hyS0z_acMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dil_block(in_c, out_c):\n",
        "    conv = nn.Sequential(\n",
        "        nn.Conv2d(in_c, out_c, kernel_size=3, stride=1, padding=1, dilation=1),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.Conv2d(out_c, out_c, kernel_size=3, stride=1, padding=1, dilation=1),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.Conv2d(out_c, out_c, kernel_size=3, stride=1, padding=2, dilation=2),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.Conv2d(out_c, out_c, kernel_size=3, stride=1, padding=2, dilation=2),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "\n",
        "        )\n",
        "    return conv\n",
        "\n",
        "\n",
        "def encoding_block(in_c, out_c):\n",
        "    conv = nn.Sequential(\n",
        "        nn.Conv2d(in_c, out_c, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        )\n",
        "    return conv\n",
        "\n",
        "def encoding_block1(in_c, out_c):\n",
        "    conv = nn.Sequential(\n",
        "        nn.Conv2d(in_c, out_c, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.Conv2d(out_c, out_c, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        )\n",
        "    return conv"
      ],
      "metadata": {
        "id": "2nHmL3XFZ1lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaeRNrQDZOMN"
      },
      "outputs": [],
      "source": [
        "class unet_model(nn.Module):\n",
        "    def __init__(self,out_channels=4,features=[16, 32]):\n",
        "        super(unet_model,self).__init__()\n",
        "\n",
        "\n",
        "        self.dil1 = dil_block(3,features[0])\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "\n",
        "        self.dil2 = dil_block(features[0],features[0])\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "\n",
        "        self.dil3 = dil_block(features[0],features[0])\n",
        "\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "\n",
        "        self.dil4 = dil_block(features[0],features[0])\n",
        "\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "\n",
        "        self.bott = encoding_block1(features[0],features[0])\n",
        "\n",
        "        self.tconv1 = nn.ConvTranspose2d(features[0], features[0], kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv1 = encoding_block(features[1],features[0])\n",
        "\n",
        "        self.tconv2 = nn.ConvTranspose2d(features[0], features[0], kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = encoding_block(features[1],features[0])\n",
        "\n",
        "        self.tconv3 = nn.ConvTranspose2d(features[0], features[0], kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = encoding_block(features[1],features[0])\n",
        "\n",
        "        self.tconv4 = nn.ConvTranspose2d(features[0], features[0], kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv4 = encoding_block1(features[1],features[0])\n",
        "\n",
        "\n",
        "        self.final_layer = nn.Conv2d(features[0],out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        dil_1 = self.dil1(x)\n",
        "\n",
        "        pool_1 = self.pool1(dil_1)\n",
        "\n",
        "        dil_2 = self.dil2(pool_1)\n",
        "\n",
        "        pool_2 = self.pool2(dil_2)\n",
        "\n",
        "        dil_3 = self.dil3(pool_2)\n",
        "\n",
        "        pool_3 = self.pool3(dil_3)\n",
        "\n",
        "        dil_4 = self.dil4(pool_3)\n",
        "\n",
        "        pool_4 = self.pool4(dil_4)\n",
        "\n",
        "        bott = self.bott(pool_4)\n",
        "\n",
        "        tconv_1 = self.tconv1(bott)\n",
        "\n",
        "        concat1 = torch.cat((tconv_1, dil_4), dim=1)\n",
        "\n",
        "        conv_1 = self.conv1(concat1)\n",
        "\n",
        "        tconv_2 = self.tconv2(conv_1)\n",
        "\n",
        "        concat2 = torch.cat((tconv_2, dil_3), dim=1)\n",
        "\n",
        "        conv_2 = self.conv2(concat2)\n",
        "\n",
        "        tconv_3 = self.tconv3(conv_2)\n",
        "\n",
        "        concat3 = torch.cat((tconv_3, dil_2), dim=1)\n",
        "\n",
        "        conv_3 = self.conv3(concat3)\n",
        "\n",
        "        tconv_4 = self.tconv4(conv_3)\n",
        "\n",
        "        concat4 = torch.cat((tconv_4, dil_1), dim=1)\n",
        "\n",
        "        conv_4 = self.conv4(concat4)\n",
        "\n",
        "\n",
        "        x = self.final_layer(conv_4)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"gpu\""
      ],
      "metadata": {
        "id": "Zh39vmrmah4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initilize the model\n",
        "model = unet_model().to(device)"
      ],
      "metadata": {
        "id": "uWZ-Oim5awHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pixel_accuracy(output, mask):\n",
        "    with torch.no_grad():\n",
        "        preds = torch.argmax(F.softmax(output, dim=1), dim=1)\n",
        "        num_correct = (preds == mask).sum()\n",
        "        num_pixels = torch.numel(preds)\n",
        "        accuracy = float(num_correct) / float(num_pixels)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "TEYDfA5Vak0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mIoU(pred_mask, mask, smooth=1e-10, n_classes=4):\n",
        "    with torch.no_grad():\n",
        "        pred_mask = F.softmax(pred_mask, dim=1)\n",
        "        pred_mask = torch.argmax(pred_mask, dim=1)\n",
        "        pred_mask = pred_mask.contiguous().view(-1)\n",
        "        mask = mask.contiguous().view(-1)\n",
        "\n",
        "        iou_per_class = []\n",
        "        for clas in range(0, n_classes): #loop per pixel class\n",
        "            true_class = pred_mask == clas\n",
        "            true_label = mask == clas\n",
        "\n",
        "            if true_label.long().sum().item() == 0: #no exist label in this loop\n",
        "                iou_per_class.append(np.nan)\n",
        "            else:\n",
        "                intersect = (true_class[true_label]).sum().float().item()\n",
        "\n",
        "                union = (true_class + true_label).sum().float().item() - intersect\n",
        "\n",
        "                iou = (intersect + smooth) / (union +smooth)\n",
        "                iou_per_class.append(iou)\n",
        "        return np.nanmean(iou_per_class)"
      ],
      "metadata": {
        "id": "FAhhi4oDamts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-05)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "uasOtxwwgkT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "val_loss = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "train_IoU = []\n",
        "val_IoU = []"
      ],
      "metadata": {
        "id": "muRsDV55azqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_accumulation_steps = 5"
      ],
      "metadata": {
        "id": "by-Hzxd0ONjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_loss = np.Inf\n",
        "best_iou_score = 0.0\n",
        "epochs = 300\n",
        "fit_time = time.time()\n",
        "for epoch in range(epochs):\n",
        "    print('Epoch: [{}/{}]'.format(epoch+1, epochs))\n",
        "\n",
        "    trainloss = 0\n",
        "    trainaccuracy = 0\n",
        "    trainIoU = 0\n",
        "\n",
        "    since = time.time()\n",
        "    model.train()\n",
        "    #for img,label in tqdm(train_loader):\n",
        "    for index, batch in enumerate(train_loader):\n",
        "        img, label = batch\n",
        "        '''\n",
        "            Traning the Model.\n",
        "        '''\n",
        "        optimizer.zero_grad()\n",
        "        img=img.float()\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        model = model.cuda()\n",
        "        output = model(img)\n",
        "        loss = criterion(output,label)\n",
        "        loss.backward()\n",
        "        if (index + 1) % gradient_accumulation_steps == 0:\n",
        "           optimizer.step()\n",
        "        #scheduler.step()\n",
        "        trainloss+=loss.item()\n",
        "        trainaccuracy += pixel_accuracy(output, label)\n",
        "        trainIoU += mIoU(output, label)\n",
        "\n",
        "    #if(i%5==0):\n",
        "        #show(img,output,label)\n",
        "\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    valloss = 0\n",
        "    valaccuracy = 0\n",
        "    valIoU = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for img_val,label_val in tqdm(valid_loader):\n",
        "        '''\n",
        "            Validation of Model.\n",
        "        '''\n",
        "        img_val=img_val.float()\n",
        "        img_val = img_val.to(device)\n",
        "        label_val = label_val.to(device)\n",
        "        model = model.cuda()\n",
        "        output_val = model(img_val)\n",
        "        loss_val = criterion(output_val,label_val)\n",
        "        valloss+=loss_val.item()\n",
        "        valaccuracy += pixel_accuracy(output_val, label_val)\n",
        "        valIoU += mIoU(output_val, label_val)\n",
        "\n",
        "    train_loss.append(trainloss/len(train_loader))\n",
        "    train_accuracy.append(trainaccuracy/len(train_loader))\n",
        "    train_IoU.append(trainIoU/len(train_loader))\n",
        "    val_loss.append(valloss/len(valid_loader))\n",
        "    val_accuracy.append(valaccuracy/len(valid_loader))\n",
        "    val_IoU.append(valIoU/len(valid_loader))\n",
        "\n",
        "    # Save model if a better val IoU score is obtained\n",
        "    if best_loss > valloss:\n",
        "         best_loss = valloss\n",
        "         torch.save({\n",
        "            'epoch': epochs,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': criterion,\n",
        "            }, 'path to save the model')\n",
        "         print('Loss_Model saved!')\n",
        "\n",
        "    # Save model if a better val IoU score is obtained\n",
        "    if best_iou_score < valIoU:\n",
        "         best_iou_score = valIoU\n",
        "         torch.save({\n",
        "            'epoch': epochs,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': criterion,\n",
        "            }, 'path to save the model')\n",
        "         print('IOU_Model saved!')\n",
        "\n",
        "    #print(\"epoch : {} ,train loss : {} ,valid loss : {} ,train acc : {} ,val acc : {} \".format(i,train_loss[-1],val_loss[-1],train_accuracy[-1],val_accuracy[-1]))\n",
        "    print(#\"Epoch:{}\".format(epoch),\n",
        "          \"Train Loss: {}\".format(trainloss/len(train_loader)),\n",
        "          \"Val Loss: {}\".format(valloss/len(valid_loader)),\n",
        "          \"Train mIoU:{}\".format(trainIoU/len(train_loader)),\n",
        "          \"Val mIoU: {}\".format(valIoU/len(valid_loader)),\n",
        "          \"Train Acc:{}\".format(trainaccuracy/len(train_loader)),\n",
        "          \"Val Acc:{}\".format(valaccuracy/len(valid_loader)),\n",
        "          \"Time: {:.2f}m\".format((time.time()-since)/60))\n",
        "print('Total time: {:.2f} m' .format((time.time()- fit_time)/60))"
      ],
      "metadata": {
        "id": "k7zQTJ0Ba1c8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(14, 5))\n",
        "ax1 = fig.add_subplot()\n",
        "plt.plot(train_loss,color='b',label='train loss', marker='o')\n",
        "plt.plot(val_loss,color='r',label = 'val loss', marker='o')\n",
        "ax1.set_title(\"Loss\")\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "CgPuJu83PPU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(14, 5))\n",
        "ax1 = fig.add_subplot()\n",
        "plt.plot(train_IoU,color='b',label='train IoU', marker='*')\n",
        "plt.plot(val_IoU,color='r',label = 'val IoU', marker='*')\n",
        "ax1.set_title(\"IoU\")\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('IoU')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "qyXT-PmY6Orj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(14, 5))\n",
        "ax1 = fig.add_subplot()\n",
        "plt.plot(train_accuracy,color='b',label='train acc', marker='*')\n",
        "plt.plot(val_accuracy,color='r',label = 'val acc', marker='*')\n",
        "ax1.set_title(\"Accuracy\")\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "Z829w3K2PU-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the trained model\n",
        "Test_model = unet_model().to(device) # initilize the model"
      ],
      "metadata": {
        "id": "fE3kklYeroIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model checkpoint\n",
        "Test_checkpoint_iou = torch.load('load the model')\n",
        "# load model weights state_dict\n",
        "Test_model.load_state_dict(Test_checkpoint_iou['model_state_dict'])\n",
        "print('Previously trained model weights state_dict loaded...')"
      ],
      "metadata": {
        "id": "Lf-7myiGrs_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create test dataset\n",
        "test_dataset = DIVA(\n",
        "    test_img_paths,\n",
        "    test_mask_paths,\n",
        ")\n",
        "\n",
        "test_dataloader_realD = DataLoader(test_dataset)"
      ],
      "metadata": {
        "id": "r-8psvQGr6_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSES = ['bg', 'line', 'hline', 'gline']"
      ],
      "metadata": {
        "id": "Bg6s0eKOsXc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import jaccard_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "nb_classes = 4\n",
        "\n",
        "# Initialize the prediction and label lists(tensors)\n",
        "predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "lbllist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(test_dataset):\n",
        "        #inputs = inputs.transpose(2,0,1)\n",
        "        inputs = inputs.to(device).unsqueeze(0)\n",
        "        classes = classes.to(device)\n",
        "        outputs = Test_model(inputs.float())\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        # Append batch prediction results\n",
        "        predlist=torch.cat([predlist,preds.view(-1).cpu()])\n",
        "        lbllist=torch.cat([lbllist,classes.view(-1).cpu()])\n",
        "\n",
        "# Confusion matrix\n",
        "conf_mat=confusion_matrix(lbllist.numpy(), predlist.numpy())\n",
        "print(conf_mat)\n",
        "\n",
        "# Per-class accuracy\n",
        "class_accuracy=100*conf_mat.diagonal()/conf_mat.sum(1)\n",
        "print(class_accuracy)\n",
        "print(classification_report(lbllist.numpy(), predlist.numpy(), target_names = CLASSES))\n",
        "\n",
        "#Jaccard, precision, recall, F1\n",
        "Jaccard = jaccard_score(lbllist.numpy(), predlist.numpy(), average=\"macro\")\n",
        "Jaccard_classes = jaccard_score(lbllist.numpy(), predlist.numpy(), average=None)\n",
        "P_R_F1 = precision_recall_fscore_support(lbllist.numpy(), predlist.numpy(), average=\"macro\")\n",
        "P, R, F1, _ = precision_recall_fscore_support(lbllist.numpy(), predlist.numpy(), average=None)\n",
        "print('Macro Jaccard:', Jaccard)\n",
        "print('Jaccard per class:', Jaccard_classes)\n",
        "print('Macro Precision, Recall, F1:', P_R_F1)\n",
        "print('Precision per class:', P)\n",
        "print('Recall per class:', R)\n",
        "print('F1 per class:', F1)"
      ],
      "metadata": {
        "id": "XPNOf8VBaKRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalise\n",
        "import seaborn as sns\n",
        "cmn = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(cmn, annot=True, fmt='.4f', xticklabels=CLASSES, yticklabels=CLASSES)\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show(block=False)"
      ],
      "metadata": {
        "id": "CISkqaZ-ETnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualization\n",
        "label_name = ['background', 'comments', 'decor', 'text']\n",
        "label_colors = np.array([background, comments, decor, text])"
      ],
      "metadata": {
        "id": "Hz3c1OPQTY3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(temp):\n",
        "    r = temp.copy()\n",
        "    g = temp.copy()\n",
        "    b = temp.copy()\n",
        "    for l in range(len(label_colors)):\n",
        "        r[temp==l]=label_colors[l,0]\n",
        "        g[temp==l]=label_colors[l,1]\n",
        "        b[temp==l]=label_colors[l,2]\n",
        "\n",
        "    rgb = np.zeros((temp.shape[0], temp.shape[1], 3))\n",
        "    rgb[:,:,0] = (r/255.0)#[:,:,0]\n",
        "    rgb[:,:,1] = (g/255.0)#[:,:,1]\n",
        "    rgb[:,:,2] = (b/255.0)#[:,:,2]\n",
        "    return rgb"
      ],
      "metadata": {
        "id": "rofTaKtGTfF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "rwG4c_ShTi9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = Path('path to save predictions')\n",
        "output_path.mkdir(exist_ok=True)"
      ],
      "metadata": {
        "id": "BxHU_UMVTleG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(test_dataset)):\n",
        "\n",
        "\n",
        "        image, mask = test_dataset[i]\n",
        "        x_tensor = image.to(device).unsqueeze(0)\n",
        "        pr_mask = Test_model(x_tensor.float())\n",
        "        pr_mask_show = (pr_mask.squeeze().cpu().detach().numpy())\n",
        "        pr_mask_show_2=np.argmax(pr_mask_show.transpose((1, 2, 0)), axis=2)\n",
        "        diva_out = (visualize(pr_mask_show_2)*255).astype(np.uint8)\n",
        "        diva_out=Image.fromarray(diva_out)\n",
        "        diva_out.save(f'path to save predictions/image_{i}.gif')"
      ],
      "metadata": {
        "id": "v6cikts0Twwi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}